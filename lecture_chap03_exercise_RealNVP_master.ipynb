{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "lecture_chap03_exercise_RealNVP_master.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takbull/U-Tokyo-Deep-Generative-Model-Spring-Seminar/blob/master/lecture_chap03_exercise_RealNVP_master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObXzbJ_in1g6",
        "colab_type": "text"
      },
      "source": [
        "# 第3回 講義 演習 Real NVPの実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmP5Q7N8n1g7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /root/userspace/chap03\n",
        "\n",
        "import PIL\n",
        "PIL.PILLOW_VERSION = PIL.__version__\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils as utils\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader \n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from utils.norm_util import get_norm_layer, get_param_groups, WNConv2d\n",
        "from utils.optim_util import bits_per_dim, clip_grad_norm\n",
        "from utils.shell_util import AverageMeter\n",
        "from utils.resnet import ResidualBlock, ResNet\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "import pylab as pl\n",
        "\n",
        "import functools\n",
        "from enum import IntEnum\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXRHcCDsn1hA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjB1jsZcn1hE",
        "colab_type": "text"
      },
      "source": [
        "## 1. 前準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CChlqCZn1hF",
        "colab_type": "text"
      },
      "source": [
        "### 1.1. データローダー"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2WTJ2twn1hF",
        "colab_type": "text"
      },
      "source": [
        "学習用のデータとしてcifar10を使用します。以下でそのためのデータローダを用意します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz3ZeEpAn1hH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "num_workers =8\n",
        "\n",
        "transform_train = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()])\n",
        "transform_test = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "trainloader = DataLoader(datasets.CIFAR10(root='data/cifar10/', train=True, download=True, transform=transform_train),\n",
        "                         batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "\n",
        "testloader = DataLoader(datasets.CIFAR10(root='data/cifar10/', train=False, download=True, transform=transform_test),\n",
        "                        batch_size=batch_size, shuffle=False, num_workers=num_workers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfHd6T3vn1hK",
        "colab_type": "text"
      },
      "source": [
        "### 1.2. 学習プロセスの表示のための関数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_PP3NAsn1hL",
        "colab_type": "text"
      },
      "source": [
        "モデルの学習中に、bpdの推移過程と生成例を表示するための関数です。学習のときに使用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8_TPz8yn1hM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_process(train_bpd, samples, image_frame_dim=4, fix=True):\n",
        "    plt.gcf().clear()\n",
        "        \n",
        "    fig = plt.figure(figsize=(24, 15))\n",
        "    fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05, wspace=0.05)\n",
        "        \n",
        "    x = range(len(train_bpd))\n",
        "\n",
        "    y = train_bpd\n",
        "    \n",
        "    ax1 = fig.add_subplot(1, 2, 1)\n",
        "\n",
        "    ax1.plot(x, y, label='train_bpd')\n",
        "\n",
        "    ax1.set_xlabel('Iter')\n",
        "    ax1.set_ylabel('bpd')\n",
        "\n",
        "    ax1.legend(loc='upper right')\n",
        "    ax1.grid(True)\n",
        "    \n",
        "    for i in range(image_frame_dim*image_frame_dim):\n",
        "        ax = fig.add_subplot(image_frame_dim, image_frame_dim*2, (int(i/image_frame_dim)+1)*image_frame_dim+i+1, xticks=[], yticks=[])\n",
        "        ax.imshow(samples[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqMXfPKQn1hP",
        "colab_type": "text"
      },
      "source": [
        "## 2. Real NVPの実装"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXA9w-wgn1hQ",
        "colab_type": "text"
      },
      "source": [
        "### 2.1. 関数・クラスの実装"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_NDil_Bn1hQ",
        "colab_type": "text"
      },
      "source": [
        "ネットワークの定義に必要な各種関数・クラスを実装します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zgyoDc9n1hR",
        "colab_type": "text"
      },
      "source": [
        "#### squeezing operation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEb8w_MNn1hR",
        "colab_type": "text"
      },
      "source": [
        "`squeeze_2x2()`は各チャネルを2x2のサイズに分割する処理を行います。  \n",
        "- `alt_order=True`を指定することで順番を変えることができます。  \n",
        "- `reverse=True`では逆の処理を行います。（分割されたものを元のサイズに戻す処理）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iinUUYqn1hS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def squeeze_2x2(x, reverse=False, alt_order=False):\n",
        "    block_size = 2\n",
        "    if alt_order:\n",
        "        n, c, h, w = x.size()\n",
        "\n",
        "        if reverse:\n",
        "            c //= 4\n",
        "        # Defines permutation of input channels (shape is (4, 1, 2, 2)).\n",
        "        squeeze_matrix = torch.tensor([[[[1., 0.], [0., 0.]]],\n",
        "                                       [[[0., 0.], [0., 1.]]],\n",
        "                                       [[[0., 1.], [0., 0.]]],\n",
        "                                       [[[0., 0.], [1., 0.]]]], \n",
        "                                       dtype=x.dtype, device=x.device)\n",
        "        perm_weight = torch.zeros((4 * c, c, 2, 2), dtype=x.dtype, device=x.device)\n",
        "        for c_idx in range(c):\n",
        "            slice_0 = slice(c_idx * 4, (c_idx + 1) * 4)\n",
        "            slice_1 = slice(c_idx, c_idx + 1)\n",
        "            perm_weight[slice_0, slice_1, :, :] = squeeze_matrix\n",
        "        shuffle_channels = torch.tensor([c_idx * 4 for c_idx in range(c)]\n",
        "                                      + [c_idx * 4 + 1 for c_idx in range(c)]\n",
        "                                      + [c_idx * 4 + 2 for c_idx in range(c)]\n",
        "                                      + [c_idx * 4 + 3 for c_idx in range(c)])\n",
        "        perm_weight = perm_weight[shuffle_channels, :, :, :]\n",
        "\n",
        "        if reverse:\n",
        "            x = F.conv_transpose2d(x, perm_weight, stride=2)\n",
        "        else:\n",
        "            x = F.conv2d(x, perm_weight, stride=2)\n",
        "    else:\n",
        "        b, c, h, w = x.size()\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "\n",
        "        if reverse:\n",
        "            x = x.view(b, h, w, c // 4, 2, 2)\n",
        "            x = x.permute(0, 1, 4, 2, 5, 3)\n",
        "            x = x.contiguous().view(b, 2 * h, 2 * w, c // 4)\n",
        "        else:\n",
        "            x = x.view(b, h // 2, 2, w // 2, 2, c)\n",
        "            x = x.permute(0, 1, 3, 5, 2, 4)\n",
        "            x = x.contiguous().view(b, h // 2, w // 2, c * 4)\n",
        "\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm-1UMgun1hW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example\n",
        "a = torch.Tensor([i+1 for i in range(16)]).view(1,1,4,4) #元のテンソル\n",
        "a_2x2 = squeeze_2x2(a) # 分割\n",
        "a_2x2alt = squeeze_2x2(a, alt_order=True) # 順番を変えて分割\n",
        "a_reverse = squeeze_2x2(a_2x2, reverse=True) # 分割されたものをもとのサイズに戻す\n",
        "print(a)\n",
        "print(a_2x2)\n",
        "print(a_2x2alt)\n",
        "print(a_reverse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BwCqXULn1hZ",
        "colab_type": "text"
      },
      "source": [
        "#### Coupling layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5aypCfun1ha",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"./image/figure3.png\" align=left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWvyZjR7n1hb",
        "colab_type": "text"
      },
      "source": [
        "Real NVPでは$D$次元の$x$のうち、$x_{1:d}$と$x_{d+1:D}$がそれぞれ**Coupling layer**の入力として与えられます。  \n",
        "その際の出力は以下の式のように表されます。  \n",
        "$y_{1:d}=x_{1:d}$  \n",
        "$y_{d+1:D} = x_{d+1:D}\\odot \\exp(s(x_{1:d})+t(x_{1:d}))$  \n",
        "この変換におけるJacobianは下三角行列となるためその行列式は  \n",
        "$\\exp(\\sum_{j} s(x_{1:d})_{j} )$となり、簡単に計算を行うことができます。  \n",
        "また、Coupling layerは逆の計算も容易に行うことができます。  \n",
        "$x_{1:d}=y_{1:d}$  \n",
        "$x_{d+1:D} = (y_{d+1:D}-t(y_{1:d}))\\odot \\exp(-s(y_{1:d}))$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPOTb506n1hb",
        "colab_type": "text"
      },
      "source": [
        "実装上はbinary mask $b$を利用します。（後述するcheckboard pattern maskとchannel-wise masking）    \n",
        "$y = b \\odot x + (1-b) \\odot (x \\odot \\exp(s(b\\odot x))+t(b\\odot x))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQagW1Yzn1hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CouplingLayer(nn.Module):\n",
        "    def __init__(self, in_channels, mid_channels, num_blocks, mask_type, reverse_mask):\n",
        "        super(CouplingLayer, self).__init__()\n",
        "\n",
        "        # Save mask info\n",
        "        self.mask_type = mask_type # CHECKBOARD(=0) or CHANNEL_WISE(=1)\n",
        "        self.reverse_mask = reverse_mask # True or False\n",
        "\n",
        "        # Build scale and translate network\n",
        "        if self.mask_type == MaskType.CHANNEL_WISE:\n",
        "            in_channels //= 2\n",
        "        self.st_net = ResNet(in_channels, mid_channels, 2 * in_channels,\n",
        "                             num_blocks=num_blocks, kernel_size=3, padding=1,\n",
        "                             double_after_norm=(self.mask_type == MaskType.CHECKERBOARD))\n",
        "\n",
        "        # Learnable scale for s\n",
        "        self.scale = nn.utils.weight_norm(Scalar())\n",
        "\n",
        "    def forward(self, x, sldj=None, reverse=True):\n",
        "        if self.mask_type == MaskType.CHECKERBOARD:\n",
        "            # Checkerboard mask\n",
        "            b = checkerboard_mask(x.size(2), x.size(3), self.reverse_mask, device=x.device)\n",
        "            x_b = x * b\n",
        "            st = self.st_net(x_b)\n",
        "            s, t = st.chunk(2, dim=1)\n",
        "            s = self.scale(torch.tanh(s))\n",
        "            s = s * (1 - b)\n",
        "            t = t * (1 - b)\n",
        "\n",
        "            # Scale and translate\n",
        "            if reverse:\n",
        "                inv_exp_s = s.mul(-1).exp()\n",
        "                x = x * inv_exp_s - t\n",
        "            else:\n",
        "                exp_s = s.exp()\n",
        "                x = (x + t) * exp_s\n",
        "\n",
        "                # Add log-determinant of the Jacobian\n",
        "                sldj += s.view(s.size(0), -1).sum(-1)\n",
        "        else:\n",
        "            # Channel-wise mask\n",
        "            if self.reverse_mask:\n",
        "                x_id, x_change = x.chunk(2, dim=1)\n",
        "            else:\n",
        "                x_change, x_id = x.chunk(2, dim=1)\n",
        "\n",
        "            st = self.st_net(x_id)\n",
        "            s, t = st.chunk(2, dim=1)\n",
        "            s = self.scale(torch.tanh(s))\n",
        "\n",
        "            # Scale and translate\n",
        "            if reverse:\n",
        "                inv_exp_s = s.mul(-1).exp()\n",
        "                x_change = x_change * inv_exp_s - t\n",
        "            else:\n",
        "                exp_s = s.exp()\n",
        "                x_change = (x_change + t) * exp_s\n",
        "\n",
        "                # Add log-determinant of the Jacobian\n",
        "                sldj += s.view(s.size(0), -1).sum(-1)\n",
        "\n",
        "            if self.reverse_mask:\n",
        "                x = torch.cat((x_id, x_change), dim=1)\n",
        "            else:\n",
        "                x = torch.cat((x_change, x_id), dim=1)\n",
        "\n",
        "        return x, sldj\n",
        "\n",
        "class Scalar(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Scalar, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.weight * x\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olF_tmMIn1he",
        "colab_type": "text"
      },
      "source": [
        "#### Masking schemes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doVhWwQnn1hf",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"./image/figure4.png\" align=left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LktnWJ1cn1hg",
        "colab_type": "text"
      },
      "source": [
        "coupling layerで使用するmasking方式には**checkboard pattern mask**と**channel-wise masking**の2つが存在します。  \n",
        "- checkboard pattern maskでは0と1が交互に並んだマスクを適用します。\n",
        "- channel-wise maskingでは`squeeze_2x2()`で分割したチャネルのうち前半を1、後半を0とします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06GL60M2n1hg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def checkerboard_mask(height, width, reverse=False, dtype=torch.float32,\n",
        "                      device=None, requires_grad=False):\n",
        "    ###### checkerboard ######\n",
        "    # [[0, 1, 0, ..., 1, 0, 1],\n",
        "    #  [1, 0, 1, ..., 0, 1, 0],\n",
        "    #  [0, 1, 0, ..., 1, 0, 1],\n",
        "    #  ...,                    \n",
        "    #  [1, 0, 1, ..., 0, 1, 0],\n",
        "    #  [0, 1, 0, ..., 1, 0, 1],\n",
        "    #  [1, 0, 1, ..., 0, 1, 0]]\n",
        "    \n",
        "    checkerboard = [[((i % 2) + j) % 2 for j in range(width)] for i in range(height)]\n",
        "    mask = torch.tensor(checkerboard, dtype=dtype, device=device, requires_grad=requires_grad)\n",
        "\n",
        "    if reverse:\n",
        "        mask = 1 - mask\n",
        "\n",
        "    # Reshape to (1, 1, height, width) for broadcasting with tensors of shape (B, C, H, W)\n",
        "    mask = mask.view(1, 1, height, width)\n",
        "\n",
        "    return mask\n",
        "\n",
        "class MaskType(IntEnum):\n",
        "    CHECKERBOARD = 0\n",
        "    CHANNEL_WISE = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ83YFuYn1hl",
        "colab_type": "text"
      },
      "source": [
        "### 2.2. ネットワークの定義"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIuatexHn1hn",
        "colab_type": "text"
      },
      "source": [
        "Coupling_Layer(checkboard) x3 -> squeezing -> Coupling_Layer(channel-wise) x3 -> unsqueezing -> Coupling_Layer(checkboard) x4  \n",
        "という構成のネットワークを定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ldrIxBvn1hn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RealNVPModule(nn.Module):\n",
        "    def __init__(self, scale_idx, num_scales, in_channels, mid_channels, num_blocks):\n",
        "        super(RealNVPModule, self).__init__()\n",
        "\n",
        "        self.is_last_block = scale_idx == num_scales - 1\n",
        "\n",
        "        self.in_couplings = nn.ModuleList([\n",
        "            CouplingLayer(in_channels, mid_channels, num_blocks, MaskType.CHECKERBOARD, reverse_mask=False),\n",
        "            CouplingLayer(in_channels, mid_channels, num_blocks, MaskType.CHECKERBOARD, reverse_mask=True),\n",
        "            CouplingLayer(in_channels, mid_channels, num_blocks, MaskType.CHECKERBOARD, reverse_mask=False)\n",
        "        ])\n",
        "\n",
        "        if self.is_last_block:\n",
        "            self.in_couplings.append(\n",
        "                CouplingLayer(in_channels, mid_channels, num_blocks, MaskType.CHECKERBOARD, reverse_mask=True))\n",
        "        else:\n",
        "            self.out_couplings = nn.ModuleList([\n",
        "                CouplingLayer(4 * in_channels, 2 * mid_channels, num_blocks, MaskType.CHANNEL_WISE, reverse_mask=False),\n",
        "                CouplingLayer(4 * in_channels, 2 * mid_channels, num_blocks, MaskType.CHANNEL_WISE, reverse_mask=True),\n",
        "                CouplingLayer(4 * in_channels, 2 * mid_channels, num_blocks, MaskType.CHANNEL_WISE, reverse_mask=False)\n",
        "            ])\n",
        "            self.next_block = RealNVPModule(scale_idx + 1, num_scales, 2 * in_channels, 2 * mid_channels, num_blocks)\n",
        "\n",
        "    def forward(self, x, sldj, reverse=False):\n",
        "        if reverse:\n",
        "            if not self.is_last_block:\n",
        "                # Re-squeeze -> split -> next block\n",
        "                x = squeeze_2x2(x, reverse=False, alt_order=True)\n",
        "                x, x_split = x.chunk(2, dim=1)\n",
        "                x, sldj = self.next_block(x, sldj, reverse)\n",
        "                x = torch.cat((x, x_split), dim=1)\n",
        "                x = squeeze_2x2(x, reverse=True, alt_order=True)\n",
        "\n",
        "                # Squeeze -> 3x coupling (channel-wise)\n",
        "                x = squeeze_2x2(x, reverse=False)\n",
        "                for coupling in reversed(self.out_couplings):\n",
        "                    x, sldj = coupling(x, sldj, reverse)\n",
        "                x = squeeze_2x2(x, reverse=True)\n",
        "\n",
        "            for coupling in reversed(self.in_couplings):\n",
        "                x, sldj = coupling(x, sldj, reverse)\n",
        "        else:\n",
        "            for coupling in self.in_couplings:\n",
        "                x, sldj = coupling(x, sldj, reverse)\n",
        "\n",
        "            if not self.is_last_block:\n",
        "                # Squeeze -> 3x coupling (channel-wise)\n",
        "                x = squeeze_2x2(x, reverse=False)\n",
        "                for coupling in self.out_couplings:\n",
        "                    x, sldj = coupling(x, sldj, reverse)\n",
        "                x = squeeze_2x2(x, reverse=True)\n",
        "\n",
        "                # Re-squeeze -> split -> next block\n",
        "                x = squeeze_2x2(x, reverse=False, alt_order=True)\n",
        "                x, x_split = x.chunk(2, dim=1)\n",
        "                x, sldj = self.next_block(x, sldj, reverse)\n",
        "                x = torch.cat((x, x_split), dim=1)\n",
        "                x = squeeze_2x2(x, reverse=True, alt_order=True)\n",
        "\n",
        "        return x, sldj"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQREN3eRn1hq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RealNVP(nn.Module):\n",
        "    def __init__(self, num_scales=2, in_channels=3, mid_channels=64, num_blocks=8):\n",
        "        super(RealNVP, self).__init__()\n",
        "        self.register_buffer('data_constraint', torch.tensor([0.9], dtype=torch.float32))\n",
        "\n",
        "        self.flows = RealNVPModule(0, num_scales, in_channels, mid_channels, num_blocks)\n",
        "\n",
        "    def forward(self, x, reverse=False):\n",
        "        sldj = None\n",
        "        if not reverse:\n",
        "            # De-quantize and convert to logits\n",
        "            x, sldj = self._pre_process(x)\n",
        "\n",
        "        x, sldj = self.flows(x, sldj, reverse)\n",
        "\n",
        "        return x, sldj\n",
        "\n",
        "    def _pre_process(self, x):\n",
        "        y = (x * 255. + torch.rand_like(x)) / 256.\n",
        "        y = (2 * y - 1) * self.data_constraint\n",
        "        y = (y + 1) / 2\n",
        "        y = y.log() - (1. - y).log()\n",
        "\n",
        "        # Save log-determinant of Jacobian of initial transform\n",
        "        ldj = F.softplus(y) + F.softplus(-y) \\\n",
        "            - F.softplus((1. - self.data_constraint).log() - self.data_constraint.log())\n",
        "        sldj = ldj.view(ldj.size(0), -1).sum(-1)\n",
        "\n",
        "        return y, sldj"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeESlyTTn1hs",
        "colab_type": "text"
      },
      "source": [
        "ロス関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_vXwIGQn1ht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RealNVPLoss(nn.Module):\n",
        "    def __init__(self, k=256):\n",
        "        super(RealNVPLoss, self).__init__()\n",
        "        self.k = k\n",
        "\n",
        "    def forward(self, z, sldj):\n",
        "        prior_ll = -0.5 * (z ** 2 + np.log(2 * np.pi))\n",
        "        prior_ll = prior_ll.view(z.size(0), -1).sum(-1) - np.log(self.k) * np.prod(z.size()[1:])\n",
        "        ll = prior_ll + sldj\n",
        "        nll = -ll.mean()\n",
        "\n",
        "        return nll"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EXqd90Dn1hv",
        "colab_type": "text"
      },
      "source": [
        "## 3. モデルの学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0tdCmfLn1hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RealNVP(num_scales=2, in_channels=3, mid_channels=64, num_blocks=8)\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H7apCJ1n1hy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight_decay = 5e-5\n",
        "lr = 1e-3\n",
        "train_bpd = []\n",
        "\n",
        "loss_fn = RealNVPLoss()\n",
        "param_groups = get_param_groups(model, weight_decay, norm_suffix='weight_g')\n",
        "optimizer = optim.Adam(param_groups, lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oiGvIn_n1h1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch, model, trainloader, device, optimizer, loss_fn, max_grad_norm):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    model.train()\n",
        "    loss_meter = AverageMeter()\n",
        "    with tqdm(total=len(trainloader.dataset)) as progress_bar:\n",
        "        for x, _ in trainloader:\n",
        "            x = x.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            z, sldj = model(x, reverse=False)\n",
        "            loss = loss_fn(z, sldj)\n",
        "            loss_meter.update(loss.item(), x.size(0))\n",
        "            loss.backward()\n",
        "            clip_grad_norm(optimizer, max_grad_norm)\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_bpd.append(bits_per_dim(x, loss_meter.avg))\n",
        "            progress_bar.set_postfix(loss=loss_meter.avg,\n",
        "                                     bpd=bits_per_dim(x, loss_meter.avg))\n",
        "            progress_bar.update(x.size(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7GwFU9Dn1h6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(model, batch_size, device):\n",
        "    z = torch.randn((batch_size, 3, 32, 32), dtype=torch.float32, device=device)\n",
        "    x, _ = model(z, reverse=True)\n",
        "    x = torch.sigmoid(x)\n",
        "    x = x.detach().cpu().numpy().transpose(0, 2, 3, 1)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9r2fLsDn1h-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(epoch, model, testloader, device, loss_fn, num_samples):\n",
        "    global best_loss\n",
        "    model.eval()\n",
        "    loss_meter = AverageMeter()\n",
        "    with torch.no_grad():\n",
        "        with tqdm(total=len(testloader.dataset)) as progress_bar:\n",
        "            for x, _ in testloader:\n",
        "                x = x.to(device)\n",
        "                z, sldj = model(x, reverse=False)\n",
        "                loss = loss_fn(z, sldj)\n",
        "                loss_meter.update(loss.item(), x.size(0))\n",
        "                \n",
        "                progress_bar.set_postfix(loss=loss_meter.avg,\n",
        "                                         bpd=bits_per_dim(x, loss_meter.avg))\n",
        "                progress_bar.update(x.size(0))\n",
        "\n",
        "    # Save samples and data\n",
        "    images = sample(model, num_samples, device)\n",
        "    display_process(train_bpd, images, image_frame_dim=4, fix=True)\n",
        "    display.clear_output(wait=True)\n",
        "    display.display(pl.gcf())\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFIHNNPSn1iB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_epoch = 0\n",
        "num_epochs = 15\n",
        "max_grad_norm = 100.\n",
        "num_samples = 64\n",
        "best_loss = 0\n",
        "for epoch in range(start_epoch, start_epoch + num_epochs):\n",
        "        train(epoch, model, trainloader, device, optimizer, loss_fn, max_grad_norm)\n",
        "        test(epoch, model, testloader, device, loss_fn, num_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApKEUS7in1iD",
        "colab_type": "text"
      },
      "source": [
        "## 4.結果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCoMNEmMn1iE",
        "colab_type": "text"
      },
      "source": [
        "目安時間: 1epochあたり20分"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBGOhrwQn1iE",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"./image/result2.png\" aling=left>"
      ]
    }
  ]
}